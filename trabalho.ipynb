{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "chWt6qmvwluC"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "sns.set(rc={'figure.figsize':(10,5)})\n",
        "sns.set_theme(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "gCxWUQqwwluE",
        "outputId": "1f1664e6-c0fd-4948-9de3-3eb3e181b78f"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-38caa99020f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/genres_v2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/genres_v2.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"data/genres_v2.csv\", low_memory=False)\n",
        "print(df.columns)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y0qYJ8iwluF"
      },
      "outputs": [],
      "source": [
        "df['duration_ms'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttiCm0b4wluG"
      },
      "source": [
        "Algumas das features não tem significado nenhum na hora de tentarmos prever o gênero da música (como _ID_, _URI_, duração, etc), sendo assim, iremos tirá-los do dataset para continuarmos a análise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykXxwb7wwluH"
      },
      "outputs": [],
      "source": [
        "df.drop(['type', 'id', 'uri', 'track_href', 'analysis_url', 'duration_ms', 'song_name', 'Unnamed: 0', 'title'], axis=1, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egMf1TIcwluI"
      },
      "source": [
        "Apenas para contexo, uma explicação melhor de cada uma dessas features pode ser encontrada [aqui](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-audio-features).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al0gGPVOwluJ"
      },
      "source": [
        "#### **Tratamento de dados inválidos**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLD9HvtbwluK"
      },
      "source": [
        "- Procurando por *NaN* e *None*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "NdrNVqCKwluL",
        "outputId": "6d65bca3-5598-4bed-dfeb-73697bad36e3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6cc656c51d22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "df.isnull().sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayrWqtXy0Kuh"
      },
      "source": [
        "Como não há valores nulos, podemos prosseguir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D01TXXj0wluN"
      },
      "source": [
        "- Procurando por valores divergentes do esperado pela documentação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1pVLFe3wluO"
      },
      "outputs": [],
      "source": [
        "count = df.shape[0]\n",
        "df.drop(df[(df['danceability'] > 1) | (df['danceability'] < 0)].index, inplace=True)\n",
        "print(\"Dropped by danceability: \", count - df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSjo1oL3wluP"
      },
      "outputs": [],
      "source": [
        "count = df.shape[0]\n",
        "df.drop(df[(df['energy'] > 1) | (df['energy'] < 0)].index, inplace=True)\n",
        "print(\"Dropped by energy: \", count - df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDVS9LYQwluQ"
      },
      "outputs": [],
      "source": [
        "count = df.shape[0]\n",
        "df.drop(df[(df['key'] > 11) | (df['key'] < -1)].index, inplace=True)\n",
        "print(\"Dropped by key: \", count - df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXYk48kAwluQ"
      },
      "outputs": [],
      "source": [
        "count = df.shape[0]\n",
        "df.drop(df[(df['loudness'] > 0) | (df['loudness'] < -60)].index, inplace=True)\n",
        "print(\"Dropped by loudness: \", count - df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqSqJVPcwluR"
      },
      "outputs": [],
      "source": [
        "count = df.shape[0]\n",
        "df.drop(df[(df['mode'] != 1) & (df['mode'] != 0)].index, inplace=True)\n",
        "print(\"Dropped by mode: \", count - df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZhmYU6wwluS"
      },
      "outputs": [],
      "source": [
        "count = df.shape[0]\n",
        "df.drop(df[(df['speechiness'] > 1) | (df['speechiness'] < 0)].index, inplace=True)\n",
        "print(\"Dropped by speechiness: \", count - df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk9MSKJbwluT"
      },
      "outputs": [],
      "source": [
        "count = df.shape[0]\n",
        "df.drop(df[(df['acousticness'] > 1) | (df['acousticness'] < 0)].index, inplace=True)\n",
        "print(\"Dropped by acousticness: \", count - df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn-mvvLFwluU"
      },
      "outputs": [],
      "source": [
        "count = df.shape[0]\n",
        "df.drop(df[(df['instrumentalness'] > 1) | (df['instrumentalness'] < 0)].index, inplace=True)\n",
        "print(\"Dropped by instrumentalness: \", count - df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Duxl2z2CwluU"
      },
      "outputs": [],
      "source": [
        "count = df.shape[0]\n",
        "df.drop(df[(df['liveness'] > 1) | (df['liveness'] < 0)].index, inplace=True)\n",
        "print(\"Dropped by liveness: \", count - df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kc8TbpHYwluV"
      },
      "outputs": [],
      "source": [
        "count = df.shape[0]\n",
        "df.drop(df[(df['valence'] > 1) | (df['valence'] < 0)].index, inplace=True)\n",
        "print(\"Dropped by valence: \", count - df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyAmtQ5n1qQa"
      },
      "source": [
        "Como é possível ver, os dados estão de acordo com a documentação e completos, sendo assim podemos realizar a analise deles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUY8UU3PwluV"
      },
      "source": [
        "#### **Análise Inicial dos Dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUf6rW5dwluV"
      },
      "source": [
        "- Quantidade de músicas por gênero:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNVP_PkuwluW"
      },
      "outputs": [],
      "source": [
        "mean_count = df.groupby('genre').count().mean()[0]\n",
        "\n",
        "f, ax = plt.subplots(1, 1, figsize=(30, 6))\n",
        "sns.histplot(df, x='genre', ax=ax)\n",
        "ax.axhline(mean_count, linestyle='dashed', label='mean', color='red')\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49YyJY1gwluW"
      },
      "source": [
        "Como podemos ver, o dataset está bem desbalanceado. Para balancear vamos fazer duas coisas:\n",
        "* Retirar o genero 'Pop', já que o mesmo possui poucos dados quanto comparado ao resto.\n",
        "* Diminuir o número de músicas do DarkTrap e Undergroup Rap para o valor médio de músicas por gênero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAUcAXCFwluW"
      },
      "outputs": [],
      "source": [
        "df.drop(df[df['genre'] == 'Pop' ].index, inplace=True)\n",
        "\n",
        "dt_count = df[df['genre'] == 'Dark Trap'].shape[0]\n",
        "df.drop(df[df['genre'] == 'Dark Trap'].sample(int(dt_count - mean_count)).index, inplace=True)\n",
        "\n",
        "ur_count = df[df['genre'] == 'Underground Rap'].shape[0]\n",
        "df.drop(df[df['genre'] == 'Underground Rap'].sample(int(ur_count - mean_count)).index, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3zsMO6bwluX"
      },
      "source": [
        "Desse modo, teremos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E63wDsOnwluX"
      },
      "outputs": [],
      "source": [
        "mean_count = df.groupby('genre').count().mean()[0]\n",
        "\n",
        "f, ax = plt.subplots(1, 1, figsize=(30, 6))\n",
        "sns.histplot(df, x='genre', ax=ax)\n",
        "ax.axhline(mean_count, linestyle='dashed', label='new mean', color='red')\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGL3rowCwluX"
      },
      "source": [
        "Agora que está mais balanceado, iremos verificar a correlação entre as variáveis que utilizaremos para determinar o gênero:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXYU0PabwluY"
      },
      "outputs": [],
      "source": [
        "corr = df.corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(corr, cmap='Blues', interpolation='none', aspect='auto')\n",
        "plt.colorbar()\n",
        "plt.xticks(range(len(corr)), corr.columns, rotation='vertical')\n",
        "plt.yticks(range(len(corr)), corr.columns);\n",
        "plt.suptitle('Correlation between variables', fontsize=15, fontweight='bold')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qIXXRQlwluY"
      },
      "source": [
        "É possível ver que, no geral, as features são pouco correlacionadas. Alguns pares, como *loudness-energy* e *valence-danceability* são mais interligados, porém não são correlacionados o suficiente para podermos simplesmente ignorar um dos elemento de cada par."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1uC-ssywluZ"
      },
      "source": [
        "#### **Normalizando os dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pRi3FxewluZ"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxufbfXfwlua"
      },
      "source": [
        "#### **Análise e Redução da Dimensionalidade**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue-CX1TUwlua"
      },
      "outputs": [],
      "source": [
        "pca = PCA()\n",
        "pca.fit(X)\n",
        "\n",
        "exp_var_cumul = {   'Número de Componentes': range(1, X.shape[1] + 1),\n",
        "                    'Variância Explicada': np.cumsum(pca.explained_variance_ratio_)\n",
        "                }\n",
        "\n",
        "\n",
        "f, ax = plt.subplots(1, 1)\n",
        "\n",
        "plt.xlabel('Número de Componentes')\n",
        "plt.ylabel('Variância Explicada Acumulada')\n",
        "\n",
        "ax.fill_between(exp_var_cumul['Número de Componentes'], exp_var_cumul['Variância Explicada'])\n",
        "ax.plot(exp_var_cumul['Número de Componentes'], exp_var_cumul['Variância Explicada'], 'ro--')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2X6rnMLwlub"
      },
      "source": [
        "Utilizando o PCA para visualizar a classificação com 2 componentes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSwyWkXNwluc"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2)\n",
        "Xt = pca.fit_transform(X)\n",
        "\n",
        "\n",
        "# Adicionando uma columna novo onde as classes se tornam numéricas\n",
        "df['num_genre'] = 0\n",
        "uniq_genres = df['genre'].unique()\n",
        "i = 0\n",
        "for genre in uniq_genres:\n",
        "    df['num_genre'] = np.where(df[\"genre\"] == genre, i, df['num_genre'])\n",
        "    i += 1\n",
        "\n",
        "plt.scatter(Xt[:,0], Xt[:,1], c=df['num_genre'], alpha = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvPA5AqJwluc"
      },
      "outputs": [],
      "source": [
        "for label in uniq_genres:\n",
        "    plt.scatter(Xt[y==label, 0], Xt[y==label, 1], label=label)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kIkIP5k64QJR"
      },
      "source": [
        "O resultado da visualização **não** ficou muito satisfatório, portanto iremos testar com T-SNE\n",
        "\n",
        "T-SNE (t-distributed Stochastic Neighbor Embedding) é um algoritmo de visualização de dados usado para reduzir a dimensionalidade de um conjunto de dados com alta dimensionalidade para que possa ser visualizado em um gráfico bidimensional. É particularmente útil para visualizar clusters ou padrões em conjuntos de dados de alta dimensionalidade, como imagens ou texto.\n",
        "\n",
        "O T-SNE funciona comparando as distâncias entre os pontos de dados no espaço de alta dimensionalidade e, em seguida, mapeando essas distâncias para o espaço de baixa dimensionalidade de maneira a manter a relação de distância o máximo possível. Isso significa que os pontos de dados que estão próximos uns dos outros no espaço de alta dimensionalidade serão colocados próximos uns dos outros no gráfico de visualização, enquanto os pontos de dados que estão distantes uns dos outros no espaço de alta dimensionalidade serão colocados distantes uns dos outros no gráfico de visualização.\n",
        "\n",
        "Um dos principais benefícios do T-SNE é que ele é muito bom em preservar a estrutura dos dados, o que significa que os padrões e clusters presentes nos dados de alta dimensionalidade são geralmente visíveis no gráfico de visualização. No entanto, o T-SNE também é conhecido por ser um pouco lento e por ter dificuldade em lidar com conjuntos de dados muito grandes.\n",
        "\n",
        "A principal diferença entre T-SNE e PCA é como eles reduzem a dimensionalidade dos dados. O PCA é um algoritmo linear que procura encontrar as direções de maior variação nos dados e, em seguida, projeta os dados nessas direções. Isso significa que o PCA é mais adequado para conjuntos de dados que seguem uma distribuição linear e tem uma variação clara. Além disso, o PCA é muito rápido e pode lidar com conjuntos de dados muito grandes, mas é menos bom em preservar a estrutura dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPfH6epFwlud"
      },
      "outputs": [],
      "source": [
        "tsne = TSNE(n_components=2)\n",
        "z = tsne.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcramJMWwlud"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x=z[:, 0], y=z[:, 1], hue=df.genre.tolist(),\n",
        "                palette=sns.color_palette(\"hls\", 14)).set(title=\"T-SNE Projection\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWlh1ijYwlud"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIefaskB4hPw"
      },
      "source": [
        "Realizando One-Hot-Enconding do *target* para separar as diferentes classes, evitando, assim, a imposição de uma ordenação implícita."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjc0-CzNwlue"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "y_train = enc.fit_transform(y_train.to_numpy().reshape(-1, 1))\n",
        "y_test = enc.fit_transform(y_test.to_numpy().reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7t5bXww5RmH"
      },
      "source": [
        "Optamos por usar técnicas de *boosting* para classificação, uma vez que se mostram muito eficientes em conjuntos de dados tabulares.\n",
        "\n",
        "O boosting é um método de aprendizado de máquina que se baseia em criar um conjunto de classificadores fracos e, em seguida, combiná-los em um classificador forte. Os classificadores fracos são modelos que são ligeiramente melhores do que o acaso, mas ainda não são suficientemente precisos por si só. No entanto, quando combinados, os classificadores fracos podem produzir um classificador forte que é muito mais preciso.\n",
        "\n",
        "O processo de boosting é realizado iterativamente. Em cada iteração, um novo classificador é treinado e adicionado ao conjunto de classificadores. O conjunto de classificadores é atualizado para dar mais peso aos exemplos que foram classificados incorretamente pelos classificadores anteriores, de modo que os novos classificadores possam se concentrar em corrigir esses erros. Isso permite que os classificadores sejam \"apostos\" uns nos outros, resultando em um classificador final mais preciso.\n",
        "\n",
        "O boosting é amplamente utilizado em muitos tipos diferentes de algoritmos de aprendizado de máquina, incluindo árvores de decisão, regressão logística e muito mais. Alguns exemplos populares de algoritmos de boosting incluem o XGBoost e o AdaBoost.\n",
        "\n",
        "XGBoost é uma implementação avançada de árvores de decisão, um tipo de algoritmo de aprendizado de máquina supervisionado. Ele funciona construindo uma série de árvores de decisão em um conjunto de dados de treinamento e, em seguida, as usa para prever valores em um conjunto de dados de teste. Cada árvore de decisão é criada a partir de uma amostra aleatória do conjunto de dados de treinamento e é treinada usando um algoritmo de otimização, como o gradiente aumentado. As árvores são então combinadas para formar o modelo final, que é usado para fazer previsões.\n",
        "\n",
        "Uma das principais vantagens do XGBoost é que ele é muito eficiente e rápido no treinamento de modelos. Isso é devido ao uso de técnicas avançadas de otimização, como o gradiente aumentado, bem como à implementação deficiente em código nativo. Além disso, o XGBoost fornece uma série de opções de tunagem de modelo, como regularização e seleção de características, o que o torna um poderoso ferramenta para otimizar o desempenho do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGJsjBelwlue"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'max_depth': range (2, 5, 1),\n",
        "    'n_estimators': range(60, 140, 40),\n",
        "    'learning_rate': [0.1, 0.01, 0.05]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG3uVwNMwluf"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier(objective= 'binary:logistic', nthread=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7Z4cKfuwluf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=parameters, scoring = 'roc_auc', n_jobs = 10, cv = 10, verbose=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCIzm4Hqwlug"
      },
      "outputs": [],
      "source": [
        "grid_search.fit(x_train, y_train.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DwKXPyYwlug"
      },
      "outputs": [],
      "source": [
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hrbTHtEwluh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(best_model, x_train, y_train.toarray(), cv=5)\n",
        "print(\"Acurácia média no Cross-Validation de treino: %.2f\" % scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU_qErZPwluh"
      },
      "outputs": [],
      "source": [
        "scores = cross_val_score(best_model, x_test, y_test.toarray(), cv=5)\n",
        "print(\"Acurácia média no Cross-Validation de teste: %.2f\" % scores.mean())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "feels",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15 (default, Nov 24 2022, 14:38:14) [MSC v.1916 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "96c036006878e132fd35cfb4f575b35765dfdecaa5cb220f776dd40cd73d89ad"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
